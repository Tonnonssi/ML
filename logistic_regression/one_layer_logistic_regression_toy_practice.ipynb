{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c098d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d2fe3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "num_sample = 500\n",
    "\n",
    "data0 = np.random.randn(num_sample,2) + (2,2)\n",
    "data1 = np.random.randn(num_sample,2) + (-2,-2)\n",
    "\n",
    "data0 = np.hstack([data0,np.zeros((num_sample,1),dtype=float)])\n",
    "data1 = np.hstack([data1,np.ones((num_sample,1),dtype=float)])\n",
    "\n",
    "data = np.vstack([data0,data1]) # 두 라벨의 데이터를 쭉 쌓음 \n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0bbe230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11002ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are assuming one layer logistic regression\n",
    "# 학습 파라미터의 개수 \n",
    "w = np.random.randn(2,1)\n",
    "b = np.random.randn(1,1)\n",
    "eta = 1e-5 # learning rate\n",
    "delta = 1e-10 # prevent log 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca4b0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(val):\n",
    "    return 1 / (1 + np.exp(-val))\n",
    "\n",
    "def grad_sigmoid(val):\n",
    "    return sigmoid(val) * (1 - sigmoid(val))\n",
    "\n",
    "def loss_ftn(pred, target, delta=1e-10):\n",
    "    pred = np.clip(pred, delta, 1 - delta) # delta로 계산 폭주 방지 \n",
    "    return -target*np.log(pred) - (1 - target)*np.log(1 - pred)\n",
    "\n",
    "def grad_loss_ftn(pred, target):\n",
    "    return -(target / pred) + ((1 - target) / (1 - pred))\n",
    "\n",
    "def compute_loss_and_grad(data_instance):\n",
    "    \"\"\"\n",
    "    나는 이걸 단계별로 구현했는데, chain-rule을 이용해 미분한 식을 만든 뒤에 값을 다 넣어도 됨 \n",
    "    ㄴ 당연한거 아닌가요?\n",
    "    ㄴ 헷갈릴 수도 있지. \n",
    "    \"\"\"\n",
    "    x, y = data_instance\n",
    "\n",
    "    # forward pass\n",
    "    h = x @ w + b\n",
    "    pred = sigmoid(h)\n",
    "    loss = loss_ftn(pred, y)\n",
    "\n",
    "    # backward pass \n",
    "    grad_loss = grad_loss_ftn(pred, y)\n",
    "    grad_sig = grad_sigmoid(h)\n",
    "\n",
    "    grad_w = (grad_loss * grad_sig).T @ x  # (1,1) * (1,2) -> (1,2)\n",
    "    grad_b = np.sum(grad_loss * grad_sig)  # (1,1) -> scalar\n",
    "\n",
    "    # 정답 예측 \n",
    "    hit = (np.round(pred) == y).astype(int)\n",
    "\n",
    "    return loss, (grad_w.T, grad_b), hit\n",
    "\n",
    "def update_parameters(params, grads):\n",
    "    w, b = params\n",
    "    grad_w, grad_b = grads\n",
    "\n",
    "    w -= eta * grad_w  # (2,1)\n",
    "    b -= eta * grad_b  # (1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9591e77c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zl/ljg24f_15m93w7f2rt14c2n80000gn/T/ipykernel_86376/2644411146.py:25: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(\"Epoch %d Train: %.3f / %.2f %%\" % (i, loss_train, acc_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train: 1.050 / 33.90 %\n",
      "Epoch 5 Train: 0.921 / 42.70 %\n",
      "Epoch 10 Train: 0.813 / 50.40 %\n",
      "Epoch 15 Train: 0.723 / 56.70 %\n",
      "Epoch 20 Train: 0.647 / 63.20 %\n",
      "Epoch 25 Train: 0.582 / 67.90 %\n",
      "Epoch 30 Train: 0.528 / 72.50 %\n",
      "Epoch 35 Train: 0.482 / 76.40 %\n",
      "Epoch 40 Train: 0.442 / 80.20 %\n",
      "Epoch 45 Train: 0.408 / 83.90 %\n",
      "Epoch 50 Train: 0.379 / 85.80 %\n",
      "Epoch 55 Train: 0.353 / 88.10 %\n",
      "Epoch 60 Train: 0.330 / 89.60 %\n",
      "Epoch 65 Train: 0.310 / 90.90 %\n",
      "Epoch 70 Train: 0.293 / 92.50 %\n",
      "Epoch 75 Train: 0.277 / 93.00 %\n",
      "Epoch 80 Train: 0.263 / 94.10 %\n",
      "Epoch 85 Train: 0.250 / 94.50 %\n",
      "Epoch 90 Train: 0.238 / 95.10 %\n",
      "Epoch 95 Train: 0.228 / 95.60 %\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    perm = np.random.permutation(len(data))\n",
    "    data = data[perm]\n",
    "\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    for j in range(len(data)):\n",
    "        x = data[j][:-1].reshape(1, -1)\n",
    "        y = data[j][-1]\n",
    "        y = np.array(y).reshape(1, 1)\n",
    "\n",
    "        params = (w, b)\n",
    "        loss, grads, n_correct = compute_loss_and_grad((x, y))\n",
    "        total_loss += loss\n",
    "        count += n_correct\n",
    "        update_parameters(params, grads)\n",
    "\n",
    "    loss_train = total_loss / len(data)\n",
    "    acc_train = (count / len(data)) * 100\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        print(\"Epoch %d Train: %.3f / %.2f %%\" % (i, loss_train, acc_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9478f788",
   "metadata": {},
   "source": [
    "반복횟수, lr와 같은 지표를 성능을 올리기 위해 고민해보기  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fbeed1",
   "metadata": {},
   "source": [
    "근데 그거 생각해도 많이 큰데 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
